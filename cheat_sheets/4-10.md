---
Class: Big Data
---

1. quiz this thurs is only on section 1-7, the stuff we've already covered
2. we haven't seen any errors yet! will see that with unique constraints
3. reminder- to figure out whether something blocks look at the table
4. and for implicit stuff you can check the implicit documentation!
5. this week is about preparing for hw and lab
6. common volumes ./:/tmp/db - matches your proj folder to the /tmp/db folder
7. format for named volumes- left hand side is stuff close to you, right is far
8. if there's named volumes, docker compose down isn't enough to start from scratch, you also have to remove the volumes
9. two services in docker are two separate machines
10. remember- all ports under 1024 are root
11. if there are git submodules their information is in a file called .gitmodules
12. sql and expected folders are common structures
13. so is a `run_tests.sh` file
14. how do we use json data in postgres?
    1. denormalized strategy
        1. combining info into a single relation- you'll have redundant information
    2. normalized strategy
        1. you're splitting info into different locations
15. there are 11 normal forms in use- we don't care about this though, and only db academics really do
16. with denormalization it's really easy to get data into your db, but it's not so good
    1. it's a one line shell command in the README
    2. two gotchas though
        1. we're looping over a file where there's only one file, next time we'll use more files
        2. using denormalized rep we have no guarantees on data integrity so it's easy to add the same tweet twice- if you run the command twice for instance
            1. so after you get it working comment it out so you don't add too much data
            2. in the `docker-compose` file
17. we'll store less data with normalized format and it'll be a lot more efficient
18. how to fix your db if you fuck it up
    1. you need to delete particular docker volumes to fix this
19. if you're permanently deleting stuff make that deletion explicit
20. postgres breaks if you try to insert null values as strings
21. divide code as much as you can to get doctests
22. our job- writing the sql insert commands
23. sqlalchemy lets us handle transactions with one command
24. making this run in parallel is where the locks concerns are going to come up
25. --db needs info from the environment section of the `docker-compose.yml` file

## Links to the sections of the documentation that have the locks tables and info

implicit lock modes: https://www.postgresql.org/docs/current/explicit-locking.html

^ also has the conflict table in it

1. never have a timestamp without a timezone
2. next quiz will be a lot easier if you read and take notes on documentation
    1. he wants transaction and explicit locking
3. we're responsible for read uncommitted, read committed, and repeatable read isolation levels
4. postgres documentation is amazing- use it to learn how stuff works
5. explicit locks
    1. locking lets one session block another sec from fucking up
    2. rare in practice- usually we use implicit locks
    3. to record when something blocks circle it
    4. commands block when trying to lock a table in share mode when another session has it locked in exclusive mode
    5. your command will be blocked if the modes are incompatible
        1. share and exclusive are incompatible
        2. there's 8 different modes- there's a table that shows which ones are incompatible
        3. access exclusive blocks everything
6. deadlocks
    1. locking two different tables doesn't block
    2. when both sessions block each other it creates a deadlock and all the sessions are stopped
    3. deadlock detection is nondeterministic
        1. we can prove that it won't always be detected
        2. it's also random which session gets terminated
7. implicit locks
    1. commands all aquire implicit locks- insert is row exclusive
    2. everything postgres needs is in a table- `pg_locks` has all the locks
8. row-level locks
    1. row exclusive locks don't block with each other- this is so we can update different rows simultan
    2. learn about row level in the documentation
    3. commands interact with tables and rows in them- can block each other at either
9. if you make a typo in a transaction it gets aborted


1. next two weeks we're focusing on the hardest concept in computer science! concurrency
2. but after that the end of the semester shoudl be pretty fluffy
3. focus on extra credit stuff if you don't like your grade
4. quiz thursday is easier than previous sql quizzes if yuo know what's going on
    1. computers are allowed! - this will be true from all quizzes here on out
5. no lab this week bc cesar chavez day, and no hw
6. the references contain sql queries that solve the problems for you automatically- so read those so you don't have to think on the quiz
7. 3 more homeworks
    1. we're gonna analyze twitter using postgres
    2. the hard part is getting the data into postgres
    3. half of the points are still remaining in the class
8. all non-graduating students have an additional project that we'll talk about in a few weeks
9. reminders
    1. headers is always 23 bytes
    2. null bitmap has one bit per column in the table- if it exceeds 8 bit than the header is bigger than 24 bytes, has to be divisible by 8, so the header goes up to 32
    3. the real calculations are in the data- figure out how much in each
    4. and the overall row size has to be divisible by 8 so you need padding at the end
10. quiz
    1. two separate insert into table commands- how many does this take up?
    2. NEW- two create table commands- answer with the optimal ordering of rows to minimize disk space usage
11. to optimize disk usage
    1. order the columns from largest to smallest
12. if a type has a number in it, that's how many types it takes up
13. on the quiz a JSON is guaranteed to be null because he doesn't expect us to know how json disk space calculation works
14. you can't make id come first
15. why doesn't postgres automatically reorder columns? it's an open issue for someone to do this for them
16. if there's a tie in bytelength, the ordering doesn't matter
17. essentially all difficult bugs are concurrency bugs
18. concurrency- when multiple programs use the database at the same time
    1. this is easy for reading data- nothing special to worry about as a user
    2. for writing this is really hard
        1. embedded databases like sqlite3 don't support concurrent writes
            1. if someone asks you which rdbms to use, ask if you need concurrent writes
        2. this is why other databases are more complicated
        3. as a user there's a lot to worry about too
        4. this is a major source of nondeterminism- hard problem
        5. lots of research but not very many best practices
        6. there's impossibility theorems on concurrent writes too
    3. there's lots of tools to help you manage this-usually covered in operating systems courses
        1. semaphores, barriers, spinlocks, mutexes, etc.
        2. os-level tools are really hard to work with- so modern programing languages have specific behavior
            1. python most famously uses the asyncio module
            2. every new version since adding this module has been backwards incompatible
            3. check out the cs46 hw on this
        3. databases use transactions and locks to manage this
        4. the quiz on this- next thursday -  will be worth 16 points and seems like it's gonna be really hard
19. quiz
    1. any time there's a select statement we're required to write the output of that select statement
    2. if you just have an insert statement the output of those insert staetmens are available to all sessions- this is called a 'naked insert statement' or a 'bare insert statement'
    3. `BEGIN;` starts a 'transaction'- nothign is committed until you run `COMMIT;`
    4. `ROLLBACK;`  - forgets all the data you inserted in your `BEGIN` block
    5. remember, `SELECT` is idempotent
    6. `ABORT;` - in postgres these are identical, in other databases abort can signal an error
    7. up until now it's identical with sqlite- when we get to concurrent writes those don't work
        1. for the quiz we're only responsible for postgres though
    8. if you're inside a transaction you can see all the stuff that's publicly posted, but nothing that's privately posted
    9. when you start your transaction you can specify an isolation level
        1. if you set it to repeatable read it'll only read the data from when you ran your first select command
            1. NOT WHEN YOU STARTED THE TRANSACTION
        2. if you set it to read committed- it's the default one so it'll only read committed stuff
    10. postgres has 4 isolation levels but we don't need to know the other two

1. new extra credit on github!
2. #1 security vulnerability at websites- now it's only 10%, user input can allow sql injections
3. NEVER USE f-strings! use your library's syntax to escape this
4. in sqlalchemy this uses bind commands
5. biggest takeaway from lab/hw - there are lots of pitfalls when working with sql/python databases
    1. llms or code you don't understand is def going to fall into them
    2. they are good at finding mistakes or places to double check if you give them all the code
6. the `UNIQUE` constraint requires that there aren't any duplicate value in the column specified
7. `self.connect` creates a session- but a transaction is created inside of a section
8. if we have a value we're possibly inserting this blocks other transactions that are considering adding it if there's a unique constraints
    1. this both blocks and errors
    2. not a dirty read
        1. two transactions can interact with each other at the level of blocking and erroring- it would be a dirty read if we got the value and tried to do something with it
9. unique causes weird behavior with null- the null value never conflicts with non-nulls
    1. the null values never block each other with `UNIQUE`
    2. this is bc unique uses the `=` to check if an insert is valid, and `NULL!=NULL`
10. if something is potentially in the table and the table has a unique constraint, trying to add it will block
11. nothing is different between different isolation levels here
12. postgres puts a row level lock on the unique index when you add values
13. foriegn keys
    1. references constraint- inside of sql how they talk abouti t, but nowhere eles
    2. in order to insert value into u, value must already exist inside of the a column in the t table for `CREATE TABLE u(b INT REFERENCES t(A)) ;`
    3. must reference a unique columni n another table
        1. if it hasn't been committed yet or doesn't exist you'll get an error
    4. if you try to drop a table that has other tables that depend on it for foriegn keys you'll also get an error
14. drop cascade drops the foreign key constraints on the other tables without dropping the tables
15. deferring constraints
    1. if you add `DEFERRABLE INITIALLY DEFERRED` to the create table statement internal inconsistencis don't break until you commit
        1. so if you have two identical values in  a unique table it's okay with that until you commit
    2. it will also stop both of the conflicting commands from running- does a rollback
16. whenever there's an error in a transaction, the entire transaction is aborted
17. remember- whenever you're not in a transaction, psql adds an implicit transaction
18. for next quiz- not responsible for section 9 in old one or section 3 in new notes packet- but everything else we are
19. `PRIMARY KEY`
    1. it's unique and not null

## Quiz Notes

1. you'll get an error if an update changes the values of the table you're working on when you're at repeatable read isolation level
