---
Class: Big Data
---

1. No lab this week bc capstone presentations
2. docker silently changed the behavior of `docker volume prune` - really stupid from docker
3. btrees can't speed up regex
    1. always use the least powerful tool—regular expressions are way more powerful than like or ilike
4. today- full text search indexing
5. partial index
    1. has a where clause in the index command
    2. doesn't effect the type of scanning strategy
    3. to use it, where clause condition must match some condition in the query exactly
    4. they have fewer page reads when using select
        1. they have conditons! so they're storing less info, fewer tree entries, shorter tree, height of tree determines page reads
        2. only stores the main thing, not the condition -> so more info fits in your 8kb, higher fanout, shorter tree, determines fewer page reads
            1. this matters more bc the fanout is more mathematically important for determining height of tree
    5. also uses less disk space
        1. where clause filters info so reduces total # of rows
        2. only store one column per row
6. how does adding more columns effect scans?
    1. increases sequential scan a lot - fewer rows per page- this always needs the whole dataset
    2. index only scan stays the same- heap page content doesn't matter
    3. index scan also takes the same amt of time- always accesses exactly one page per row- no deduplication
    4. bitmap scan- has a deduplication step, fewer rows per page means fewer duplicate pages, so this takes more time
    5. aggregates and joins
        1. none are effected- get output from last step—the structure of the query and the info effects the runtime of this
6. last hw is going to do full text search
7. we can use postgres plus these queries to make full text search faster- lok at the blog links there
8. HNSW and IVFFlat require lots of math to understand- not gonna do those
9. remember- btrees can't speed up a wildcard on both ends, using tricks
10. we can use inequalities!
11. ilike isn't efficent- equivalent to a ton of less than and greater than signs- condition grows exponentially with length of word
12. one-sided wildcard queries are great for btrees tho- so like finding hashtags
13. nobody really knows how to do full text search all that well
14. its hard partially because there is no sql standard for fts and people disagree
15. most full text search is not sql-based
    1. elasticsearch - has like 90% of the market
16. most popular is acid-based—nobody understands how to do it unless you're doing it full time
17. and there's lots of docker compose annoying shit to deal with
18. lucene and solr are smilar to it- internally used in elasticsearch
19. postgres
    1. lets you do anything you like about sql- and it has the best fts capabilities
    2. disadvantages
        1. have to store tables and indexes seperately- like 2x the disk space kinda but peopel who deploy elastic usually also use postgres
        2. not as many ranking algorithms, but currently in development- it's fairly rapidly catching up but sped has slowed down in the last year or so
20. types for FTS
    1. tsvector - text that can be searched, function is `to_tsvector`
        1. have to specify the language you're searching in- postgres has like 30 european languages
        2. gives you a vector with word position and word
        3. if you specify languge it
            1. converts words into root words
            2. removes short and non-semantic words
            3. this makes search mor eaccurate
    2. tsquery- the search query, function is `to_tsquery`
        1. lots of stuff you can do- think conditions
    3. a final query uses both of these
        1. formatted something like `WHERE to_tsvector() @@ to_tsquery()`
            1. `@@` means contains
    4. there's a space/speed tradeoff for defining `ts_vectors` in your schema vs at runtime
21. we can't use btrees for fts
    1. semantically no way for it to happen
    2. @@ operator- every index can only work on a certain set of operators, btree doesn't have @@ defined for it- GIN does though!
22. GIN index
    1. its like a btree of btrees
    2. now we're not using columns themselves but subsets of the colums that contain those words
    3. inside the subtrees each word is attached to a tree that contains all the tuple ids that contain that word
    4. binary operations can be implemented in btrees in log time
    5. limitations- no multi column indexes, only supports bitmap scans so you can't get results in sorted order, so there's no way to speed up order by, all results get returned in a batch, so no way to speed up limit clause
    6. implement it by adding `USING GIN` to the end of yoru index command, before any where clauses
23. RUM index fixes both of the issues- the multicolumn and only bitmap
    1. we also store auxiliary information in addition to tuple ids
    2. the fanout stays the same size
    3. to get hte right behavior from a second column you add a keyword `WITH ('attach = {column_name}') - lets you pass the parameter to the index
    4. where isn't necessary here but still makes it faster
24. we can get ec on the final assignment for using htis on the last assignment!
25. this isn't built into postgres so we have to figure out how to install it
